{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2b79f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Decision tree !!! CART\n",
    "the problem that can be biffercated to if n else \n",
    " it can be used to predict categorical or numerical value , CLASSIFICATION N REGRESSION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444fa134",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#best feature --->entropy for each decision taking step , the max entropty is choosen!!!\n",
    "#split as per best feature criteria \n",
    "#repeat()\n",
    "next time ::::Information_gain =max(g1,g2,......gn)\n",
    "\n",
    "Features with higher information gain are considered more important for splitting, thus aiding in feature selection.\n",
    "@outlier , feature scaling , normalisation not needed to handled compulsory \n",
    "\n",
    "rootnode , spliting logic ,decision node , leaf node \n",
    "\n",
    "#best feature who can be ?\n",
    "#spliting condition ?why which \n",
    "#complexity --->subtree traversal(log depth_of_tree)\n",
    "\n",
    "what are the hyperparameter in decision tree ? \n",
    "overfiting n underfit decision tree model prediction?\n",
    "when should i stop spliting ? depth of tree ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b7ce6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Entropy :::impureity \n",
    "information gain:reduction in Entropy\n",
    "\n",
    "pruning \n",
    "early stopping \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086be452",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hiring_2023.csv')\n",
    "df.info()\n",
    "\n",
    "#eda , eda2 , \n",
    "#split in train test \n",
    "\n",
    "\n",
    "X = df.drop(['hire_status'], axis = 1)\n",
    "y = df[:-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 8, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81beba4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#optional :outlier handling , standardisation,normalisation\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dd5570",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dse = DecisionTreeClassifier(max_depth=16, random_state=8)\n",
    "dse.fit(x_train,y_train)\n",
    "y_pred=dse.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0456aa1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "importance_level=dse.feature_importances_\n",
    "\n",
    "thresold_level=0.3\n",
    "selected_features = X.columns[importances > threshold]\n",
    "x_train_updated=x_train[selected_features]\n",
    "x_test_updated=x_test[selected_features]\n",
    "\n",
    "#train it again with new feature set \n",
    "# Train a new model using the selected features\n",
    "dse_selected = DecisionTreeClassifier(max_depth=16, random_state=8)\n",
    "dse_selected.fit(X_train_selected, y_train)\n",
    "y_pred_selected_features = clf_selected.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e12d50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_selected_features =accuracy_score(y_test,y_pred_selected_featured)\n",
    "r2score(y_test,y_pred_selected_featured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2d03c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#gird search can be applied so that i get best hyperparameter n then i can use it directly for decission DecisionTreeClassifier\n",
    "\n",
    "#Dtreeviz \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
